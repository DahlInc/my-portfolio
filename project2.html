<!-- project2.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Automating Real-Time Stock Data Collection with Python: A Yahoo Finance Scraper</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <div class="container project-page">
        <h2>Automating Real-Time Stock Data Collection with Python: A Yahoo Finance Scraper</h2>

        <!-- Project Content Wrapper -->
        <div class="project-content">
            <!-- Section 1: Introduction -->
            <section class="project-section">
                <h3>Introduction</h3>
                <p>
                    I developed a robust web scraper to extract real-time stock data from Yahoo Finance using Python. The goal was to automate the collection of key financial metrics to enable in-depth analysis of various publicly traded companies. By leveraging Python libraries such as Selenium and Pandas, I was able to automate the data extraction process and subsequently clean, organize, and analyze the data.
                </p>
            </section>

            <!-- Image 1: Homepage Screenshot -->
            <div class="project-image">
                <img src="images/project2-img1.jpg" alt="Homepage Screenshot">
            </div>

            <!-- Section 2: Objectives -->
            <section class="project-section">
                <h3>Objectives</h3>
                <p>
                    The key objectives of this project were:
                    - **Automate Stock Data Collection:** Efficiently gather real-time and historical stock data for multiple companies from Yahoo Finance.
                    - **Extract Key Financial Metrics:** Capture crucial financial metrics such as stock prices, price changes, trading volume, market cap, PE ratio, EPS, and other performance indicators.
                    - **Enable Data-Driven Financial Analysis:** Provide a clean and structured dataset for further financial modeling and analysis, suitable for automated trading strategies, trend analysis, and risk assessments.
                </p>
            </section>

            <!-- Image 2: Feature Highlight -->
            <div class="project-image">
                <img src="images/project2-img2.jpg" alt="Feature Highlight">
            </div>

            <!-- Section 3: Tools and Technologies -->
            <section class="project-section">
                <h3>Tools and Technologies</h3>
                <p>
                    - **Python:** The core programming language used to build the scraper and handle the data processing.
                    - **Selenium:** Automated the interaction with Yahoo Finance’s dynamic content, especially for dealing with JavaScript-rendered elements.
                    - **Pandas:** Used for organizing the scraped data, cleaning, and preparing it for analysis.
                    - **CSV/Excel Integration:** After data extraction, I saved the output to CSV files, which were then used for financial modeling in Excel and Power BI.
                </p>
            </section>

            <!-- Image 3: Responsive Design -->
            <div class="project-image">
                <img src="images/project2-img3.jpg" alt="Responsive Design">
            </div>

            <!-- Section 4: Results -->
            <section class="project-section">
                <h3>Key Features and results</h3>
                <p>
- **Real-Time Stock Data Extraction:** The scraper dynamically retrieves stock prices, daily
highs and lows, 52-week ranges, trading volume, market capitalization, price-to-earnings (PE)
ratio, and more.
- **Error Handling and Data Validation:** Implemented robust error handling to manage potential
issues like missing data or dynamic webpage content, ensuring that the data collection process
remains uninterrupted and accurate.
- **Multi-Stock and Multi-Site Support:** The project was designed to scrape data for multiple
companies at once and can be easily extended to work with other financial data websites                
                </p>
                 <ul>
                    <li><strong>Three.js:</strong> Utilized for real-time 3D rendering, enabling the creation of dynamic and interactive 3D environments.</li>
                    <li><strong>GSAP & TWEEN.js:</strong> Employed for smooth animations and easing controls, enhancing the visual fluidity of interactions.</li>
                    <li><strong>Blender:</strong> Used to create and model the 3D ramen shop, which is then exported as a GLB file for integration into the web environment.</li>
                    <li><strong>Raycasting:</strong> Implemented in Three.js to detect and handle object clicks, allowing users to interact with various elements within the scene.</li>
                    <li><strong>OrbitControls:</strong> Provides users with the ability to rotate, zoom, and pan the camera, ensuring intuitive navigation within the 3D space.</li>
                    <li><strong>UnrealBloomPass:</strong> Adds bloom effects to certain elements like lamp posts, contributing to the cyberpunk aesthetic of the environment.</li>
                    <li><strong>Audio Integration:</strong> Background music is loaded via Three.js’s AudioLoader, immersing users further into the cyberpunk theme.</li>
                    <li><strong>Responsive Design:</strong> Ensures that the 3D environment adapts seamlessly across different devices and screen sizes.</li>
                </ul>
                <p>
                    Additionally, the implementation includes features such as a continuously spinning fan to enhance realism and dynamic lighting techniques (point, ambient, and directional lights) to create a vibrant atmosphere. The portfolio showcases clickable PNG project images that zoom into detailed views upon interaction, providing an engaging user experience.
                </p>
            </section>

            <!-- Section 5: Applications and Future Enhancements -->
            <section class="project-section">
                <h3>Applications and Future Enhancements</h3>
                <p>
                    This project is highly extensible. Moving forward, I plan to integrate more advanced data analytics techniques such as machine learning models for stock price predictions and use cloud-based services for large-scale data storage and processing. Additionally, I am exploring the use of real-time visualizations and interactive dashboards in Power BI for enhanced insights. This project demonstrates my ability to build scalable and automated solutions for financial data collection and analysis, showcasing my skills in Python, web scraping, and data science.
                </p>
            </section>
        </div>

        <!-- Navigation Button -->
        <a href="index.html" class="nav-button">Back</a>
    </div>
</body>
</html>
